{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-17T06:10:34.309936Z",
     "iopub.status.busy": "2023-05-17T06:10:34.309316Z",
     "iopub.status.idle": "2023-05-17T06:10:34.321010Z",
     "shell.execute_reply": "2023-05-17T06:10:34.320030Z",
     "shell.execute_reply.started": "2023-05-17T06:10:34.309893Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import math \n",
    "import pathlib \n",
    "import cv2\n",
    "import shutil \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import * \n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, BatchNormalization, Dropout, \\\n",
    "        LayerNormalization, GlobalAveragePooling2D, Lambda, Add, MaxPooling2D, ReLU, AveragePooling2D, LeakyReLU, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:32.464398Z",
     "iopub.status.busy": "2023-05-17T06:08:32.464020Z",
     "iopub.status.idle": "2023-05-17T06:08:32.469517Z",
     "shell.execute_reply": "2023-05-17T06:08:32.468477Z",
     "shell.execute_reply.started": "2023-05-17T06:08:32.464366Z"
    }
   },
   "outputs": [],
   "source": [
    "LAMBDA_u = 1  # ratio between the supervised loss and unsupervised loss in total loss\n",
    "TAU = 0.9  # threshold\n",
    "MU = 7    # unlabelled data ratio.\n",
    "DECAY_RATE = 0.999\n",
    "MOMENTUM = 0.9\n",
    "IMG_WIDTH = 32 \n",
    "IMG_HEIGHT = 32 \n",
    "N_CHANNELS = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:47.964271Z",
     "iopub.status.busy": "2023-05-17T06:08:47.963880Z",
     "iopub.status.idle": "2023-05-17T06:08:47.990929Z",
     "shell.execute_reply": "2023-05-17T06:08:47.989925Z",
     "shell.execute_reply.started": "2023-05-17T06:08:47.964239Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader: \n",
    "    \"\"\"\n",
    "        Class, will be useful for creating the BYOL dataset or dataset for the DownStream task \n",
    "            like classification or segmentation.\n",
    "        Methods:\n",
    "            __normalize(scope: private)\n",
    "            __preprocess_img(scope: private)\n",
    "             __get_valdata(scope: private)\n",
    "            get_vit_dataset(scope: public)\n",
    "        \n",
    "        Property:\n",
    "            dname(dtype: str)        : dataset name(supports cifar10, cifar100).\n",
    "            augmentor(type)          : byol augmentor instance/object.\n",
    "            nval(type: int)          : Number of validation data needed, this will be created by splitting the testing\n",
    "                                       data.\n",
    "            resize_shape(dtype: int) : Resize shape, bcoz pretrained models, might have a different required shape.\n",
    "            normalize(dtype: bool)   : bool value, whether to normalize the data or not. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dname=\"cifar10\", augmentor=None, unlabel_ratio=0.90,\n",
    "                                             resize_shape=32, normalize=True, mu=10, label_data_bs=32): \n",
    "        assert dname in [\"cifar10\", 'cifar100'], \"dname should be either cifar10 or cifar100\"\n",
    "        assert unlabel_ratio <= 0.99, \"ValueError: nval value should be <= 0.99\"\n",
    "        \n",
    "        __train_data, __test_data = self.__download_data(dname)\n",
    "        self.__train_X, self.__train_y = __train_data\n",
    "        self.__dtest_X, self.__dtest_y = __test_data \n",
    "        self.class_name = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                                           'dog', 'frog', 'horse', 'sheep', 'truck']\n",
    "        self.augmentor = augmentor\n",
    "        self.resize_shape = resize_shape\n",
    "        \n",
    "        self.__normalize() if normalize else None\n",
    "        self.min_obj_cov_value = 0.7\n",
    "        self.color_jitter_value = 0.1\n",
    "        self.mu = mu \n",
    "        self.__tot_num_samples = len(self.__train_X)\n",
    "        self.label_data_bs = label_data_bs\n",
    "        self.__get_unlabeled_data(unlabel_ratio)\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.__train_X.shape[0] + self.__dtest_X.shape[0]\n",
    "    \n",
    "    def __repr__(self): \n",
    "        return f\"Training Samples: {self.__train_X.shape[0]}, Testing Samples: {self.__dtest_X.shape[0]}\"\n",
    "    \n",
    "    def __download_data(self, dname):\n",
    "        \"\"\"\n",
    "            Downloads the data from the tensorflow website using the tensorflw.keras.load_data() method.\n",
    "            Params:\n",
    "                dname(type: Str): dataset name, it just supports two dataset cifar10 or cifar100\n",
    "            Return(type(np.ndarray, np.ndarray))\n",
    "                returns the training data and testing data\n",
    "        \"\"\"\n",
    "        if dname == \"cifar10\": \n",
    "            train_data, test_data = tf.keras.datasets.cifar10.load_data()\n",
    "        if dname == \"cifar100\": \n",
    "            train_data, test_data = tf.keras.datasets.cifar100.load_data()\n",
    "            \n",
    "        return train_data, test_data\n",
    "    \n",
    "    def __normalize(self): \n",
    "        \"\"\"\n",
    "            this method, will used to normalize the inputs.\n",
    "        \"\"\"\n",
    "        self.__train_X = self.__train_X / 255.0\n",
    "        self.__dtest_X = self.__dtest_X / 255.0\n",
    "    \n",
    "    def __label_preprocess(self, image, label): \n",
    "        \"\"\"\n",
    "            this method, will be used by the get_byol_dataset methos, which does a convertion of \n",
    "            numpy data to tensorflow data.\n",
    "            Params:\n",
    "                image(type: np.ndarray): image data.\n",
    "            Returns(type; (np.ndarray, np.ndarray))\n",
    "                returns the two different augmented views of same image.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            preprocessed_image = self.augmentor.weak_augment(image)\n",
    "            \n",
    "            return preprocessed_image, label\n",
    "        \n",
    "        except Exception as err:\n",
    "            return err\n",
    "        \n",
    "    def __unlabel_preprocess(self, image): \n",
    "        \"\"\"\n",
    "            this method, will be used by the get_byol_dataset methos, which does a convertion of \n",
    "            numpy data to tensorflow data.\n",
    "            Params:\n",
    "                image(type: np.ndarray): image data.\n",
    "            Returns(type; (np.ndarray, np.ndarray))\n",
    "                returns the two different augmented views of same image.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            weak_augmented_img = self.augmentor.weak_augment(image)\n",
    "            strong_augmented_img = self.augmentor.strong_augment(image)\n",
    "            \n",
    "            return (weak_augmented_img, strong_augmented_img)\n",
    "        \n",
    "        except Exception as err:\n",
    "            return err\n",
    "    \n",
    "    def get_labeled_dataset(self, dataset_type=\"train\"):\n",
    "        \"\"\"\n",
    "            this method, will gives the byol dataset, which is nothing but a tf.data.Dataset object.\n",
    "            Params:\n",
    "                batch_size(dtype: int)    : Batch Size.\n",
    "                dataset_type(dtype: str)  : which type of dataset needed, (train, test or val)\n",
    "                \n",
    "            return(type: tf.data.Dataset)\n",
    "                returns the tf.data.Dataset for intended dataset_type, by preprocessing and converting \n",
    "                the np data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if dataset_type == \"train\":\n",
    "                tensorflow_data = tf.data.Dataset.from_tensor_slices((self.__labeled_X, self.__labeled_y))\n",
    "                tensorflow_data = (\n",
    "                tensorflow_data\n",
    "                  #  .map(self.__label_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                    .shuffle(1024)\n",
    "                    .batch(self.label_data_bs, drop_remainder=True)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                )\n",
    "                return tensorflow_data  \n",
    "            \n",
    "            if dataset_type == \"test\":\n",
    "                tensorflow_data = tf.data.Dataset.from_tensor_slices((self.__dtest_X, self.__dtest_y))\n",
    "                tensorflow_data = (\n",
    "                tensorflow_data\n",
    "                    .shuffle(1024)\n",
    "                    .batch(self.label_data_bs, drop_remainder=True)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                )\n",
    "                return tensorflow_data  \n",
    "        \n",
    "        except Exception as err:\n",
    "            return err\n",
    "        \n",
    "    def get_unlabeled_dataset(self):\n",
    "        \"\"\"\n",
    "            this method, will gives the byol dataset, which is nothing but a tf.data.Dataset object.\n",
    "            Params:\n",
    "                batch_size(dtype: int)    : Batch Size.\n",
    "                dataset_type(dtype: str)  : which type of dataset needed, (train, test or val)\n",
    "                \n",
    "            return(type: tf.data.Dataset)\n",
    "                returns the tf.data.Dataset for intended dataset_type, by preprocessing and converting \n",
    "                the np data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            unlabeled_bs = self.mu * self.label_data_bs\n",
    "            tensorflow_data = tf.data.Dataset.from_tensor_slices(self.__unlabeled_X)\n",
    "            tensorflow_data = (\n",
    "                tensorflow_data\n",
    "                .map(self.__unlabel_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                .shuffle(1024)\n",
    "                .batch(unlabeled_bs, drop_remainder=True)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "            )\n",
    "            return tensorflow_data  \n",
    "        \n",
    "        except Exception as err:\n",
    "            return err\n",
    "    \n",
    "    def __get_unlabeled_data(self, unlabel_ratio):\n",
    "        \"\"\"\n",
    "            this method is used to create a labeled and unlabeled data with the unlabeled_ratio..\n",
    "            Params:\n",
    "                nval(dtype: Int); Number of validation data needed, rest of test_X.shape[0] - nval, will be \n",
    "                                  testing data size.\n",
    "            returns(type; np.ndarray, np.ndarray):\n",
    "                returns the testing and validation dataset.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            n_unlabel_data = int(unlabel_ratio * self.__tot_num_samples)\n",
    "            n_labeled_data = self.__tot_num_samples - n_unlabel_data\n",
    "            \n",
    "            ind_arr = np.arange(self.__tot_num_samples)\n",
    "            \n",
    "            labeled_inds = np.random.choice(ind_arr, n_labeled_data)\n",
    "            unlabeled_inds = [i for i in ind_arr if not i in labeled_inds]\n",
    "            \n",
    "            self.labeled_inds = labeled_inds \n",
    "            self.unlabeled_inds = unlabeled_inds\n",
    "            \n",
    "            self.__labeled_X, self.__labeled_y = self.__train_X[labeled_inds], self.__train_y[labeled_inds]\n",
    "            self.__unlabeled_X = self.__train_X[unlabeled_inds]\n",
    "        except Exception as err:\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:48.941189Z",
     "iopub.status.busy": "2023-05-17T06:08:48.940810Z",
     "iopub.status.idle": "2023-05-17T06:08:48.957322Z",
     "shell.execute_reply": "2023-05-17T06:08:48.956335Z",
     "shell.execute_reply.started": "2023-05-17T06:08:48.941157Z"
    }
   },
   "outputs": [],
   "source": [
    "class FixMatchAugmentor: \n",
    "    \"\"\"\n",
    "        This class is used for the data augmentation for the byol model.\n",
    "        Methods: \n",
    "            __random_flip(scope: private)\n",
    "            __random_zoom(scope: private)\n",
    "            augment(scope: public)\n",
    "    \"\"\"\n",
    "    def __init__(self): \n",
    "        pass \n",
    "    \n",
    "    def __random_horizontal_flip(self, image):\n",
    "        \"\"\"\n",
    "            this method does a random crop with height and width of the crop are sampled randomly. it does the \n",
    "            crop with the height and width, then it does a resizing again to the original shape. And also it does\n",
    "            a flip of the image\n",
    "            Params:\n",
    "                image(type: tf.Tensor)   : image data of type tensor.\n",
    "                resize_shape(type: int)  : Size of the image.\n",
    "            Return(type: tf.Tensor)\n",
    "                returns the crop and resized image.\n",
    "        \"\"\"\n",
    "        try:    \n",
    "            image = tf.image.random_flip_left_right(image) \n",
    "            return image\n",
    "        \n",
    "        except Exception as err:\n",
    "            return err\n",
    "    \n",
    "    @tf.function\n",
    "    def __random_zoom(self, image):\n",
    "        \"\"\"\n",
    "            this method, will do the color disortion augmentation for the given image.\n",
    "            Params:\n",
    "                image(type: tf.Tensor)   : image data of type tensor.\n",
    "            Return(type: tf.Tensor)\n",
    "                returns the crop and resized image.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            image = tf.keras.preprocessing.image.random_zoom(image, (0.5, 0.5), row_axis=0, col_axis=1, channel_axis=2)\n",
    "            image = tf.keras.preprocessing.image.random_rotation(image, 20, row_axis=0, col_axis=1, channel_axis=2)\n",
    "            return tf.convert_to_tensor(image)\n",
    "        \n",
    "        except Exception as error:\n",
    "            return error\n",
    "    \n",
    "    @tf.function\n",
    "    def weak_augment(self, image): \n",
    "        \"\"\"\n",
    "            this method will include all the augmentation as a pipeline(random crop, random flip, resize, and \n",
    "            color disortion), this augment method will be used by DataLoader class.\n",
    "            Params:\n",
    "                image(type: tf.Tensor)   : image data of type tensor.\n",
    "                resize_shape(type: int)  : Size of the image.\n",
    "            Return(type: tf.Tensor)\n",
    "                returns the crop and resized image.\n",
    "                \n",
    "        \"\"\"\n",
    "        try: \n",
    "            \n",
    "            image = self.__random_horizontal_flip(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "            image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "            return image\n",
    "        \n",
    "        except Exception as error:\n",
    "            print(error, error)\n",
    "            return error\n",
    "        \n",
    "    #@tf.function\n",
    "    def strong_augment(self, x, seed=(1, 2), rand_jpeg_quality=False, pad=4): \n",
    "        \"\"\"\n",
    "            this method will include all the augmentation as a pipeline(random crop, random flip, resize, and \n",
    "            color disortion), this augment method will be used by DataLoader class.\n",
    "            Params:\n",
    "                image(type: tf.Tensor)   : image data of type tensor.\n",
    "                resize_shape(type: int)  : Size of the image.\n",
    "            Return(type: tf.Tensor)\n",
    "                returns the crop and resized image.\n",
    "                \n",
    "        \"\"\"\n",
    "        try: \n",
    "\n",
    "            x = tf.image.random_flip_left_right(x)\n",
    "            x = tf.image.random_brightness(x, max_delta=0.9)\n",
    "            x = tf.image.random_contrast(x, lower=0.2, upper=1.8)\n",
    "\n",
    "            x = tf.image.random_hue(x, max_delta=0.2)\n",
    "            x = tf.image.random_saturation(x, lower=0.2, upper=2)\n",
    "          #  x = tf.image.random_crop(x, (16, 16, 3))\n",
    "           # x = tf.image.resize(x, (32, 32))\n",
    "\n",
    "            if rand_jpeg_quality:\n",
    "                x = tf.image.random_jpeg_quality(x, min_jpeg_quality=50, max_jpeg_quality=100)\n",
    "\n",
    "        #    x = tf.pad(x, paddings=[(0, 0), (pad, pad), (pad, pad), (0, 0)], mode=\"REFLECT\")\n",
    "          #  x = tf.image.stateless_random_crop(x, size=(32, width, 3), seed=seed)\n",
    "\n",
    "            return x\n",
    "        except Exception as error:\n",
    "            print(error, error)\n",
    "            return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:49.494176Z",
     "iopub.status.busy": "2023-05-17T06:08:49.493809Z",
     "iopub.status.idle": "2023-05-17T06:08:51.560344Z",
     "shell.execute_reply": "2023-05-17T06:08:51.559327Z",
     "shell.execute_reply.started": "2023-05-17T06:08:49.494146Z"
    }
   },
   "outputs": [],
   "source": [
    "fixmatch_data_augmentor = FixMatchAugmentor()\n",
    "fixmatch_dataloader = DataLoader(\"cifar10\", fixmatch_data_augmentor, 0.9, 32, True, MU, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:51.562748Z",
     "iopub.status.busy": "2023-05-17T06:08:51.562374Z",
     "iopub.status.idle": "2023-05-17T06:08:55.376012Z",
     "shell.execute_reply": "2023-05-17T06:08:55.374942Z",
     "shell.execute_reply.started": "2023-05-17T06:08:51.562715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method FixMatchAugmentor.weak_augment of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7cbf217ff1f0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "labeled_ds = fixmatch_dataloader.get_labeled_dataset()\n",
    "unlabeled_ds = fixmatch_dataloader.get_unlabeled_dataset()\n",
    "test_ds = fixmatch_dataloader.get_labeled_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:55.377974Z",
     "iopub.status.busy": "2023-05-17T06:08:55.377603Z",
     "iopub.status.idle": "2023-05-17T06:08:55.402218Z",
     "shell.execute_reply": "2023-05-17T06:08:55.401047Z",
     "shell.execute_reply.started": "2023-05-17T06:08:55.377938Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Residual3x3Unit(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels_in, channels_out, stride, droprate=0., activate_before_residual=False):\n",
    "        super(Residual3x3Unit, self).__init__()\n",
    "        self.bn_0 = BatchNormalization(momentum=0.999)\n",
    "        self.relu_0 = LeakyReLU(alpha=0.1)\n",
    "        self.conv_0 =Conv2D(channels_out, kernel_size=3, strides=stride, padding='same', use_bias=False)\n",
    "        self.bn_1 = BatchNormalization(momentum=0.999)\n",
    "        self.relu_1 = LeakyReLU(alpha=0.1)\n",
    "        self.conv_1 = Conv2D(channels_out, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.downsample = channels_in != channels_out\n",
    "        self.shortcut = Conv2D(channels_out, kernel_size=1, strides=stride, use_bias=False)\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "        self.dropout = Dropout(rate=droprate)\n",
    "        self.droprate = droprate\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=True):\n",
    "        if self.downsample and self.activate_before_residual:\n",
    "            x = self.relu_0(self.bn_0(x, training=training))\n",
    "        elif not self.downsample:\n",
    "            out = self.relu_0(self.bn_0(x, training=training))\n",
    "        out = self.relu_1(self.bn_1(self.conv_0(x if self.downsample else out), training=training))\n",
    "        if self.droprate > 0.:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv_1(out)\n",
    "        return out + (self.shortcut(x) if self.downsample else x)\n",
    "\n",
    "\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_units, channels_in, channels_out, unit, stride, droprate=0., activate_before_residual=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.units = self._build_unit(n_units, unit, channels_in, channels_out, stride, droprate, activate_before_residual)\n",
    "\n",
    "    def _build_unit(self, n_units, unit, channels_in, channels_out, stride, droprate, activate_before_residual):\n",
    "        units = []\n",
    "        for i in range(n_units):\n",
    "            units.append(unit(channels_in if i == 0 else channels_out, \n",
    "                        channels_out, stride if i == 0 else 1, droprate, activate_before_residual))\n",
    "        return units\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=True):\n",
    "        for unit in self.units:\n",
    "            x = unit(x, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WideResNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes, depth=28, width=2, droprate=0., input_shape=(None, 32, 32, 3), **kwargs):\n",
    "        super(WideResNet, self).__init__(input_shape, **kwargs)\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        N = int((depth - 4) / 6)\n",
    "        channels = [16, 16 * width, 32 * width, 64 * width]\n",
    "\n",
    "        self.conv_0 = tf.keras.layers.Conv2D(channels[0], kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.block_0 = ResidualBlock(N, channels[0], channels[1], Residual3x3Unit, 1, droprate, True)\n",
    "        self.block_1 = ResidualBlock(N, channels[1], channels[2], Residual3x3Unit, 2, droprate)\n",
    "        self.block_2 = ResidualBlock(N, channels[2], channels[3], Residual3x3Unit, 2, droprate)\n",
    "        self.bn_0 = BatchNormalization(momentum=0.999)\n",
    "        self.relu_0 = LeakyReLU(alpha=0.1)\n",
    "        self.avg_pool = AveragePooling2D((8, 8), (1, 1))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=True):\n",
    "        x = inputs\n",
    "        x = self.conv_0(x)\n",
    "        x = self.block_0(x, training=training)\n",
    "        x = self.block_1(x, training=training)\n",
    "        x = self.block_2(x, training=training)\n",
    "        x = self.relu_0(self.bn_0(x, training=training))\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:10:03.540485Z",
     "iopub.status.busy": "2023-05-17T06:10:03.540083Z",
     "iopub.status.idle": "2023-05-17T06:10:03.549482Z",
     "shell.execute_reply": "2023-05-17T06:10:03.548011Z",
     "shell.execute_reply.started": "2023-05-17T06:10:03.540450Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(image_size=None):\n",
    "    model = Sequential()\n",
    "  # Add the layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:55.405646Z",
     "iopub.status.busy": "2023-05-17T06:08:55.404579Z",
     "iopub.status.idle": "2023-05-17T06:08:55.535174Z",
     "shell.execute_reply": "2023-05-17T06:08:55.534252Z",
     "shell.execute_reply.started": "2023-05-17T06:08:55.405611Z"
    }
   },
   "outputs": [],
   "source": [
    "wide_resnet = WideResNet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:55.537019Z",
     "iopub.status.busy": "2023-05-17T06:08:55.536654Z",
     "iopub.status.idle": "2023-05-17T06:08:55.560856Z",
     "shell.execute_reply": "2023-05-17T06:08:55.559837Z",
     "shell.execute_reply.started": "2023-05-17T06:08:55.536984Z"
    }
   },
   "outputs": [],
   "source": [
    "wide_resnet.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:08:55.562813Z",
     "iopub.status.busy": "2023-05-17T06:08:55.562466Z",
     "iopub.status.idle": "2023-05-17T06:08:55.578852Z",
     "shell.execute_reply": "2023-05-17T06:08:55.577509Z",
     "shell.execute_reply.started": "2023-05-17T06:08:55.562780Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_pseudo_labels(weak_augmentation_predictions, threshold): \n",
    "    max_indexes = tf.math.argmax(weak_augmentation_predictions, axis=1)\n",
    "    confidence = tf.reduce_max(weak_augmentation_predictions, axis=1)\n",
    "    pseudo_labels = tf.where(confidence > threshold, max_indexes, -1)\n",
    "    \n",
    "    return pseudo_labels\n",
    "\n",
    "def train_step(model,\n",
    "               labeled_batch,\n",
    "               unlabeled_batch, \n",
    "               optimizer,\n",
    "               loss_function,\n",
    "               metric_function,\n",
    "               lambda_u,\n",
    "               tau):\n",
    "    \"\"\"\n",
    "        this method does the manual tr, ain step using the gradient tape.\n",
    "        Params: \n",
    "            x(type: tf.data.Dataset): Independent Variable of type tf.data.Dataset.\n",
    "            y(type: tf.data.Dataset): dependent Variable of type tf.data.Dataset.\n",
    "            model(type; tf.models.Model): keras model, that will be used for the prediction.\n",
    "            optimizer(tf.optimizer): Optimizer for updating the gradients.\n",
    "            loss_fn(type: tf.losses): Loss function for calculating the loss of the model.\n",
    "            train_acc_metric(type; tf.accuracy): Metric function for evaluation the data.\n",
    "            \n",
    "        Return(type: float)\n",
    "            this method returns the loss value of the training data.\n",
    "    \"\"\"\n",
    "    labeled_weak_augmentation_X, labeled_weak_augmentation_y = labeled_batch[0], labeled_batch[1]\n",
    "    unlabeled_weak_augmentation_data = unlabeled_batch[0]\n",
    "    unlabeled_strong_augmentation_data = unlabeled_batch[1]\n",
    "  #  print(labeled_weak_augmentation_X, labeled_weak_augmentation_y)\n",
    "   # print(unlabeled_weak_augmentation_data)\n",
    "    \n",
    "    num_pseudo_labels = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # labeled loss\n",
    "        y_pred = model(labeled_weak_augmentation_X)\n",
    "        labeled_loss = loss_function(labeled_weak_augmentation_y, y_pred)\n",
    "        \n",
    "        # weak augmentation prediction and pseduolabels\n",
    "        weak_augmentation_predictions = model(unlabeled_weak_augmentation_data)\n",
    "        pseudo_labels = create_pseudo_labels(weak_augmentation_predictions, tau)\n",
    "        \n",
    "        # strong augmentation\n",
    "        strong_augmentation_predictions = model(unlabeled_strong_augmentation_data)\n",
    "        filtered_pseudo_labels = tf.boolean_mask(pseudo_labels, pseudo_labels != -1)\n",
    "        filtered_y_pred_strong_augmentation = tf.boolean_mask(strong_augmentation_predictions, pseudo_labels != -1)\n",
    "        \n",
    "        if filtered_pseudo_labels.shape[0] > 0:\n",
    "            unlabeled_loss = loss_function(filtered_pseudo_labels, filtered_y_pred_strong_augmentation)\n",
    "            num_pseudo_labels += filtered_pseudo_labels.shape[0]\n",
    "        else:\n",
    "            unlabeled_loss = 0\n",
    "            \n",
    "        total_loss = labeled_loss + lambda_u * unlabeled_loss\n",
    "    \n",
    "    params = model.trainable_weights\n",
    "    grads = tape.gradient(total_loss, params)\n",
    "    optimizer.apply_gradients(zip(grads, params))\n",
    "    \n",
    "    return total_loss, labeled_loss, unlabeled_loss, num_pseudo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:10:21.347589Z",
     "iopub.status.busy": "2023-05-17T06:10:21.347175Z",
     "iopub.status.idle": "2023-05-17T06:10:21.359463Z",
     "shell.execute_reply": "2023-05-17T06:10:21.358349Z",
     "shell.execute_reply.started": "2023-05-17T06:10:21.347554Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm \n",
    "def manual_train(\n",
    "                labeled_ds,\n",
    "                unlabeled_ds,    \n",
    "                model,\n",
    "                optimizer,\n",
    "                loss_fn,\n",
    "                train_acc_metric,\n",
    "                epochs=10, \n",
    "            ):\n",
    "\n",
    "        \"\"\"\n",
    "            this method, does the manual train and test step for multiple epochs\n",
    "            Params: \n",
    "                epochs(type; int): Number of epoch model needed to be trained.\n",
    "                log_step(type:int): Number of train step.\n",
    "                val_log_step(type:int): Number of val step.\n",
    "                x(type: tf.data.Dataset): Independent Variable of type tf.data.Dataset.\n",
    "                y(type: tf.data.Dataset): dependent Variable of type tf.data.Dataset.\n",
    "                model(type; tf.models.Model): keras model, that will be used for the prediction.\n",
    "                loss_fn(type: tf.losses): Loss function for calculating the loss of the model.\n",
    "                val_acc_metric(type; tf.accuracy): Metric function for evaluation the data.\n",
    "\n",
    "        \"\"\"\n",
    "        tot_loss = []   \n",
    "        pseudo_labs = []\n",
    "        lab_losses = []\n",
    "        unlab_losses = []\n",
    "        tot_num_pseudo_lab = 0\n",
    "        tot_lab_loss = 0\n",
    "        tot_unlab_loss = 0\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "            # Iterate over the batches of the dataset\n",
    "            for step, labeled_batch in tqdm.tqdm(enumerate(labeled_ds), total=len(labeled_ds)):\n",
    "                #print(len(labeled_ds))\n",
    "                for s, unlabeled_batch in enumerate(unlabeled_ds): \n",
    "                    loss_value, lab_loss, unlab_loss, num_pseudo_lab = train_step(model,\n",
    "                                                                                labeled_batch,\n",
    "                                                                                unlabeled_batch, \n",
    "                                                                                optimizer,\n",
    "                                                                                loss_fn,\n",
    "                                                                                train_acc_metric,\n",
    "                                                                                LAMBDA_u,\n",
    "                                                                                TAU)\n",
    "                    tot_loss.append(float(loss_value))\n",
    "                    tot_num_pseudo_lab += num_pseudo_lab\n",
    "                    tot_lab_loss += lab_loss.numpy()\n",
    "                    tot_unlab_loss += unlab_loss\n",
    "                    break\n",
    "\n",
    "            # Run a validation loop at the end of each epoch\n",
    "            m_tot_loss = np.mean(tot_loss)\n",
    "            m_lab_loss = tot_lab_loss/len(tot_loss)\n",
    "            m_unlab_loss = tot_unlab_loss/len(tot_loss)\n",
    "            pseudo_labs.append(tot_num_pseudo_lab)\n",
    "            lab_losses.append(m_lab_loss)\n",
    "            unlab_losses.append(m_unlab_loss)\n",
    "            print(f\"tot_loss: {m_tot_loss} lab_loss: {m_lab_loss} unlab_loss: {m_unlab_loss} Pseudo_labs: {tot_num_pseudo_lab}\")\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                model.save(\"checkpoint_model\")\n",
    "        return model, tot_loss, lab_losses, unlab_losses, pseudo_labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T06:11:50.335150Z",
     "iopub.status.busy": "2023-05-17T06:11:50.334437Z",
     "iopub.status.idle": "2023-05-17T08:21:36.804176Z",
     "shell.execute_reply": "2023-05-17T08:21:36.803104Z",
     "shell.execute_reply.started": "2023-05-17T06:11:50.335114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 2.4031082407022133 lab_loss: 2.1810331092430997 unlab_loss: 0.22207508981227875 Pseudo_labs: 2846\n",
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 2.160464597818179 lab_loss: 1.885596161469435 unlab_loss: 0.274868369102478 Pseudo_labs: 7290\n",
      "\n",
      "Start of epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.9881986379623413 lab_loss: 1.6973500962440784 unlab_loss: 0.29084861278533936 Pseudo_labs: 9114\n",
      "\n",
      "Start of epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.8223356321836128 lab_loss: 1.5370312065650256 unlab_loss: 0.2853044271469116 Pseudo_labs: 11142\n",
      "\n",
      "Start of epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.7749915986489027 lab_loss: 1.406131183489775 unlab_loss: 0.3688604533672333 Pseudo_labs: 11586\n",
      "\n",
      "Start of epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.863495552386993 lab_loss: 1.309724855881471 unlab_loss: 0.5537707805633545 Pseudo_labs: 11371\n",
      "\n",
      "Start of epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 2.1631300984284816 lab_loss: 1.3977340498031714 unlab_loss: 0.765395998954773 Pseudo_labs: 5115\n",
      "\n",
      "Start of epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.6557935208846362 lab_loss: 1.267040348205811 unlab_loss: 0.38875314593315125 Pseudo_labs: 5661\n",
      "\n",
      "Start of epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.3927061687677333 lab_loss: 1.0930240807624965 unlab_loss: 0.299682080745697 Pseudo_labs: 7262\n",
      "\n",
      "Start of epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.3039723886893346 lab_loss: 1.0089192860401595 unlab_loss: 0.2950531244277954 Pseudo_labs: 8139\n",
      "\n",
      "Start of epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.1625212671665044 lab_loss: 0.8879442256994736 unlab_loss: 0.2745770812034607 Pseudo_labs: 9770\n",
      "\n",
      "Start of epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 1.0955539292249925 lab_loss: 0.7936205837206963 unlab_loss: 0.3019333779811859 Pseudo_labs: 10754\n",
      "\n",
      "Start of epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.9570497702329587 lab_loss: 0.6850916139590435 unlab_loss: 0.2719580829143524 Pseudo_labs: 12197\n",
      "\n",
      "Start of epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.8624048657142199 lab_loss: 0.5928311143548061 unlab_loss: 0.2695736885070801 Pseudo_labs: 13667\n",
      "\n",
      "Start of epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.764267990222344 lab_loss: 0.489142923305432 unlab_loss: 0.2751251459121704 Pseudo_labs: 15095\n",
      "\n",
      "Start of epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.6930978519794269 lab_loss: 0.4131855711531945 unlab_loss: 0.27991223335266113 Pseudo_labs: 16704\n",
      "\n",
      "Start of epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.5628323002885549 lab_loss: 0.3092762806858772 unlab_loss: 0.25355592370033264 Pseudo_labs: 18655\n",
      "\n",
      "Start of epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.502102430527791 lab_loss: 0.24853201664220065 unlab_loss: 0.25357040762901306 Pseudo_labs: 20340\n",
      "\n",
      "Start of epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.43235399870154184 lab_loss: 0.19090583349745244 unlab_loss: 0.24144816398620605 Pseudo_labs: 22040\n",
      "\n",
      "Start of epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.3596779863612774 lab_loss: 0.1424536164611196 unlab_loss: 0.2172243446111679 Pseudo_labs: 23572\n",
      "\n",
      "Start of epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.30680479663304794 lab_loss: 0.10122631801865421 unlab_loss: 0.2055784910917282 Pseudo_labs: 25210\n",
      "\n",
      "Start of epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.25055069371293753 lab_loss: 0.07654690162804073 unlab_loss: 0.17400380969047546 Pseudo_labs: 26868\n",
      "\n",
      "Start of epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.2404991287069443 lab_loss: 0.07212348103833695 unlab_loss: 0.1683756560087204 Pseudo_labs: 27603\n",
      "\n",
      "Start of epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.2405993965191719 lab_loss: 0.08088600988953541 unlab_loss: 0.15971335768699646 Pseudo_labs: 28145\n",
      "\n",
      "Start of epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.17778109477307552 lab_loss: 0.04782406670542864 unlab_loss: 0.12995702028274536 Pseudo_labs: 29264\n",
      "\n",
      "Start of epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.1427958621762884 lab_loss: 0.035420030498733886 unlab_loss: 0.10737580806016922 Pseudo_labs: 30530\n",
      "\n",
      "Start of epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.1701971784186287 lab_loss: 0.05104591506115424 unlab_loss: 0.11915123462677002 Pseudo_labs: 30633\n",
      "\n",
      "Start of epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.11585621373393597 lab_loss: 0.02737996827524442 unlab_loss: 0.08847621083259583 Pseudo_labs: 31567\n",
      "\n",
      "Start of epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.13646420108106655 lab_loss: 0.04275449831187964 unlab_loss: 0.09370969235897064 Pseudo_labs: 31716\n",
      "\n",
      "Start of epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.12497819859821063 lab_loss: 0.04007481799896759 unlab_loss: 0.08490338921546936 Pseudo_labs: 31903\n",
      "\n",
      "Start of epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.09170343862989774 lab_loss: 0.023248490375968125 unlab_loss: 0.06845492869615555 Pseudo_labs: 32676\n",
      "\n",
      "Start of epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.11567833109830435 lab_loss: 0.03861845606857409 unlab_loss: 0.07705987244844437 Pseudo_labs: 32434\n",
      "\n",
      "Start of epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.1298633072978984 lab_loss: 0.046549368366891615 unlab_loss: 0.08331392705440521 Pseudo_labs: 32321\n",
      "\n",
      "Start of epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.13162987977743912 lab_loss: 0.04450205978579246 unlab_loss: 0.08712782710790634 Pseudo_labs: 32485\n",
      "\n",
      "Start of epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.12312682051784717 lab_loss: 0.04758279990309324 unlab_loss: 0.07554399967193604 Pseudo_labs: 32706\n",
      "\n",
      "Start of epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.16941946532386234 lab_loss: 0.06967427607816763 unlab_loss: 0.09974518418312073 Pseudo_labs: 32312\n",
      "\n",
      "Start of epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.10232467968494464 lab_loss: 0.03326122862218211 unlab_loss: 0.0690634623169899 Pseudo_labs: 32876\n",
      "\n",
      "Start of epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.06269374623512611 lab_loss: 0.01425754796685233 unlab_loss: 0.048436202108860016 Pseudo_labs: 33586\n",
      "\n",
      "Start of epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.09590440750933993 lab_loss: 0.03912584804082797 unlab_loss: 0.05677855387330055 Pseudo_labs: 33359\n",
      "\n",
      "Start of epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0907474684361846 lab_loss: 0.03373888812180107 unlab_loss: 0.05700859799981117 Pseudo_labs: 33336\n",
      "\n",
      "Start of epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.06084105661377693 lab_loss: 0.01420891492624576 unlab_loss: 0.04663214460015297 Pseudo_labs: 33781\n",
      "\n",
      "Start of epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.02938039279363763 lab_loss: 0.0032826718755435045 unlab_loss: 0.02609771303832531 Pseudo_labs: 34248\n",
      "\n",
      "Start of epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.020176717093608413 lab_loss: 0.0017296298006280826 unlab_loss: 0.018447082489728928 Pseudo_labs: 34496\n",
      "\n",
      "Start of epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.028650998048341043 lab_loss: 0.006557096700607172 unlab_loss: 0.02209390327334404 Pseudo_labs: 34493\n",
      "\n",
      "Start of epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.22830904459055418 lab_loss: 0.10936188488864364 unlab_loss: 0.11894717812538147 Pseudo_labs: 32467\n",
      "\n",
      "Start of epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.17388014500148785 lab_loss: 0.08441796036472973 unlab_loss: 0.08946217596530914 Pseudo_labs: 32515\n",
      "\n",
      "Start of epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.08124723078874059 lab_loss: 0.027691191311579388 unlab_loss: 0.05355605110526085 Pseudo_labs: 33641\n",
      "\n",
      "Start of epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.05705449463895116 lab_loss: 0.01878544272151955 unlab_loss: 0.038269054144620895 Pseudo_labs: 33919\n",
      "\n",
      "Start of epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.022593496039730664 lab_loss: 0.004505214863270222 unlab_loss: 0.018088284879922867 Pseudo_labs: 34485\n",
      "\n",
      "Start of epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.01312733686585815 lab_loss: 0.0010441315147872022 unlab_loss: 0.0120832035318017 Pseudo_labs: 34684\n",
      "\n",
      "Start of epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.010231000949622681 lab_loss: 0.0007188185645995523 unlab_loss: 0.00951218418776989 Pseudo_labs: 34720\n",
      "\n",
      "Start of epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.009841614648347529 lab_loss: 0.0005675606488670709 unlab_loss: 0.009274055249989033 Pseudo_labs: 34763\n",
      "\n",
      "Start of epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.00851486609929289 lab_loss: 0.0005573401219571212 unlab_loss: 0.007957528345286846 Pseudo_labs: 34782\n",
      "\n",
      "Start of epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006908618374533641 lab_loss: 0.0004597102235540007 unlab_loss: 0.0064489091746509075 Pseudo_labs: 34810\n",
      "\n",
      "Start of epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0069018089084121855 lab_loss: 0.0004695956363903884 unlab_loss: 0.006432213820517063 Pseudo_labs: 34843\n",
      "\n",
      "Start of epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.390214500869684 lab_loss: 0.22209360425725977 unlab_loss: 0.1681208610534668 Pseudo_labs: 31670\n",
      "\n",
      "Start of epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.1346224202738645 lab_loss: 0.05723483718107813 unlab_loss: 0.07738758623600006 Pseudo_labs: 33222\n",
      "\n",
      "Start of epoch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.06240178025566424 lab_loss: 0.021175596929867587 unlab_loss: 0.041226185858249664 Pseudo_labs: 33925\n",
      "\n",
      "Start of epoch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.01565447974597844 lab_loss: 0.0020485723640050334 unlab_loss: 0.013605909422039986 Pseudo_labs: 34592\n",
      "\n",
      "Start of epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.013233952707079694 lab_loss: 0.0019018459247140877 unlab_loss: 0.011332105845212936 Pseudo_labs: 34700\n",
      "\n",
      "Start of epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.010841382229372334 lab_loss: 0.0008220706824478186 unlab_loss: 0.01001930981874466 Pseudo_labs: 34746\n",
      "\n",
      "Start of epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0077435386020881245 lab_loss: 0.000473848445025373 unlab_loss: 0.007269692607223988 Pseudo_labs: 34810\n",
      "\n",
      "Start of epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.007981058028795255 lab_loss: 0.0007099308939312976 unlab_loss: 0.007271126843988895 Pseudo_labs: 34829\n",
      "\n",
      "Start of epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.009013197663872957 lab_loss: 0.0007166865637034975 unlab_loss: 0.008296509273350239 Pseudo_labs: 34842\n",
      "\n",
      "Start of epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006262374047088461 lab_loss: 0.00039824329998667125 unlab_loss: 0.005864131264388561 Pseudo_labs: 34875\n",
      "\n",
      "Start of epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.005814247318388273 lab_loss: 0.00035104721851334593 unlab_loss: 0.005463199689984322 Pseudo_labs: 34892\n",
      "\n",
      "Start of epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006498133514795858 lab_loss: 0.00041053759865369497 unlab_loss: 0.006087594199925661 Pseudo_labs: 34860\n",
      "\n",
      "Start of epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0048075094490718 lab_loss: 0.00028674159338128776 unlab_loss: 0.00452076643705368 Pseudo_labs: 34894\n",
      "\n",
      "Start of epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.010363849376190979 lab_loss: 0.0008733336181176827 unlab_loss: 0.00949051696807146 Pseudo_labs: 34830\n",
      "\n",
      "Start of epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.45196059411272216 lab_loss: 0.26477335838736066 unlab_loss: 0.18718725442886353 Pseudo_labs: 31494\n",
      "\n",
      "Start of epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.21284209627610368 lab_loss: 0.10945200731303209 unlab_loss: 0.10339011996984482 Pseudo_labs: 32548\n",
      "\n",
      "Start of epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.04915746082014476 lab_loss: 0.0164915548480983 unlab_loss: 0.032665908336639404 Pseudo_labs: 34125\n",
      "\n",
      "Start of epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.02327504904809384 lab_loss: 0.003625047441976046 unlab_loss: 0.01965000294148922 Pseudo_labs: 34558\n",
      "\n",
      "Start of epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:43<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.009599343738488805 lab_loss: 0.0010156714050213057 unlab_loss: 0.008583669550716877 Pseudo_labs: 34814\n",
      "\n",
      "Start of epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.007379303786691684 lab_loss: 0.0005301930459259333 unlab_loss: 0.006849111057817936 Pseudo_labs: 34856\n",
      "\n",
      "Start of epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006031905950527662 lab_loss: 0.0004755540869493229 unlab_loss: 0.005556351970881224 Pseudo_labs: 34864\n",
      "\n",
      "Start of epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006066749695515356 lab_loss: 0.00035046052837573463 unlab_loss: 0.005716288462281227 Pseudo_labs: 34883\n",
      "\n",
      "Start of epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006543024115858433 lab_loss: 0.0003033757372099316 unlab_loss: 0.0062396470457315445 Pseudo_labs: 34889\n",
      "\n",
      "Start of epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.005601067782173721 lab_loss: 0.0004508194477600624 unlab_loss: 0.005150249227881432 Pseudo_labs: 34902\n",
      "\n",
      "Start of epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0039377000506740445 lab_loss: 0.00026503903648471093 unlab_loss: 0.0036726612597703934 Pseudo_labs: 34919\n",
      "\n",
      "Start of epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003708005168449838 lab_loss: 0.0002333217300667037 unlab_loss: 0.0034746844321489334 Pseudo_labs: 34914\n",
      "\n",
      "Start of epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0037922351109908703 lab_loss: 0.0002860167322080834 unlab_loss: 0.0035062176175415516 Pseudo_labs: 34902\n",
      "\n",
      "Start of epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.005945323620742271 lab_loss: 0.00019840411143598967 unlab_loss: 0.0057469201274216175 Pseudo_labs: 34902\n",
      "\n",
      "Start of epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.399293370747891 lab_loss: 0.23474622751487353 unlab_loss: 0.1645471304655075 Pseudo_labs: 31933\n",
      "\n",
      "Start of epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.13149268189683938 lab_loss: 0.0649350915818314 unlab_loss: 0.0665576159954071 Pseudo_labs: 33369\n",
      "\n",
      "Start of epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0402653363163177 lab_loss: 0.014202154259412335 unlab_loss: 0.026063183322548866 Pseudo_labs: 34353\n",
      "\n",
      "Start of epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.014082919942059865 lab_loss: 0.0022506415626384504 unlab_loss: 0.011832276359200478 Pseudo_labs: 34725\n",
      "\n",
      "Start of epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006747948965102506 lab_loss: 0.0006438679693602376 unlab_loss: 0.006104082800447941 Pseudo_labs: 34847\n",
      "\n",
      "Start of epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003916822405396185 lab_loss: 0.0002505745839162279 unlab_loss: 0.003666248172521591 Pseudo_labs: 34878\n",
      "\n",
      "Start of epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003252833093798612 lab_loss: 0.00022622499296887373 unlab_loss: 0.003026608843356371 Pseudo_labs: 34900\n",
      "\n",
      "Start of epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003094357323089543 lab_loss: 0.00027725713954104765 unlab_loss: 0.0028170994482934475 Pseudo_labs: 34913\n",
      "\n",
      "Start of epoch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.005710230101286493 lab_loss: 0.00035522451752839493 unlab_loss: 0.00535500468686223 Pseudo_labs: 34892\n",
      "\n",
      "Start of epoch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.004577182475119256 lab_loss: 0.00025665557484007176 unlab_loss: 0.004320527892559767 Pseudo_labs: 34914\n",
      "\n",
      "Start of epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0051729661227466585 lab_loss: 0.0004908766475940259 unlab_loss: 0.004682089667767286 Pseudo_labs: 34900\n",
      "\n",
      "Start of epoch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0031635760386938597 lab_loss: 0.0002599857051709711 unlab_loss: 0.0029035897459834814 Pseudo_labs: 34916\n",
      "\n",
      "Start of epoch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0035282258861862384 lab_loss: 0.00015566370367044632 unlab_loss: 0.003372562350705266 Pseudo_labs: 34912\n",
      "\n",
      "Start of epoch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0038972723440308934 lab_loss: 0.00017522518290655708 unlab_loss: 0.003722046036273241 Pseudo_labs: 34909\n",
      "\n",
      "Start of epoch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.14436380486875303 lab_loss: 0.07983859627247715 unlab_loss: 0.06452520936727524 Pseudo_labs: 34153\n",
      "\n",
      "Start of epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.3966012260852716 lab_loss: 0.2263466855033468 unlab_loss: 0.17025454342365265 Pseudo_labs: 31570\n",
      "\n",
      "Start of epoch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.09583579628871611 lab_loss: 0.04559491363276417 unlab_loss: 0.050240907818078995 Pseudo_labs: 33878\n",
      "\n",
      "Start of epoch 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.05424384724121923 lab_loss: 0.020594413109882644 unlab_loss: 0.03364943340420723 Pseudo_labs: 34436\n",
      "\n",
      "Start of epoch 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.022301579667374682 lab_loss: 0.0051095348350524246 unlab_loss: 0.017192041501402855 Pseudo_labs: 34655\n",
      "\n",
      "Start of epoch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006929451586284603 lab_loss: 0.0007216645216407741 unlab_loss: 0.006207786500453949 Pseudo_labs: 34862\n",
      "\n",
      "Start of epoch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0057847355518531865 lab_loss: 0.00031722380754800746 unlab_loss: 0.005467511713504791 Pseudo_labs: 34908\n",
      "\n",
      "Start of epoch 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.004652156339710554 lab_loss: 0.0003043319371872946 unlab_loss: 0.004347824025899172 Pseudo_labs: 34897\n",
      "\n",
      "Start of epoch 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0036325043209870225 lab_loss: 0.00028539601331163 unlab_loss: 0.0033471076749265194 Pseudo_labs: 34908\n",
      "\n",
      "Start of epoch 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003731122486500774 lab_loss: 0.00026734794054251467 unlab_loss: 0.003463775385171175 Pseudo_labs: 34923\n",
      "\n",
      "Start of epoch 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:46<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0032195640548403994 lab_loss: 0.0002102493778565053 unlab_loss: 0.003009314415976405 Pseudo_labs: 34920\n",
      "\n",
      "Start of epoch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.0035339351892710114 lab_loss: 0.00043654880882735224 unlab_loss: 0.003097386797890067 Pseudo_labs: 34913\n",
      "\n",
      "Start of epoch 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.006570545077407494 lab_loss: 0.0019670876923666395 unlab_loss: 0.0046034581027925014 Pseudo_labs: 34896\n",
      "\n",
      "Start of epoch 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.147458092109539 lab_loss: 0.0663015595540249 unlab_loss: 0.08115654438734055 Pseudo_labs: 33857\n",
      "\n",
      "Start of epoch 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.12925279541956022 lab_loss: 0.06472747136733513 unlab_loss: 0.0645253136754036 Pseudo_labs: 33878\n",
      "\n",
      "Start of epoch 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.11909999207068139 lab_loss: 0.06208055446451255 unlab_loss: 0.0570194348692894 Pseudo_labs: 33984\n",
      "\n",
      "Start of epoch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.06265740912968819 lab_loss: 0.031664245414923735 unlab_loss: 0.03099316544830799 Pseudo_labs: 34432\n",
      "\n",
      "Start of epoch 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.04222870078266192 lab_loss: 0.017416249367180663 unlab_loss: 0.024812456220388412 Pseudo_labs: 34651\n",
      "\n",
      "Start of epoch 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.026137864134328153 lab_loss: 0.00858203160219499 unlab_loss: 0.017555834725499153 Pseudo_labs: 34661\n",
      "\n",
      "Start of epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:45<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.007743018692007097 lab_loss: 0.001537925781951216 unlab_loss: 0.006205091718584299 Pseudo_labs: 34846\n",
      "\n",
      "Start of epoch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_loss: 0.003862665744143156 lab_loss: 0.000286907625776277 unlab_loss: 0.003575758310034871 Pseudo_labs: 34913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decay_steps = 1000\n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "    initial_learning_rate=0.1, decay_steps=decay_steps)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=lr_decayed_fn, nesterov=True, momentum=0.9)\n",
    "\n",
    "opt = keras.optimizers.Adam()\n",
    "wideresnet = WideResNet(10)\n",
    "model = create_model()\n",
    "loss_func = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "trained_model, train_oss, lab_loss, unlab_loss, n_pseudo_labs = manual_train(labeled_ds, unlabeled_ds, model,\n",
    "                                                                                         opt, loss_func, None, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"total_loss.obj\", \"wb\") as f:\n",
    "    pickle.dump(train_oss, f)\n",
    "    \n",
    "with open(\"label_loss.obj\", \"wb\") as f:\n",
    "    pickle.dump(lab_loss, f)\n",
    "    \n",
    "with open(\"unlabel_loss.obj\", \"wb\") as f:\n",
    "    pickle.dump(unlab_loss, f)\n",
    "    \n",
    "with open(\"n_pseudo_labels.obj\", \"wb\") as f:\n",
    "    pickle.dump(n_pseudo_labs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T08:22:13.483271Z",
     "iopub.status.busy": "2023-05-17T08:22:13.482801Z",
     "iopub.status.idle": "2023-05-17T08:22:14.339300Z",
     "shell.execute_reply": "2023-05-17T08:22:14.338302Z",
     "shell.execute_reply.started": "2023-05-17T08:22:13.483232Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model.save(\"trained_model_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T08:22:19.466713Z",
     "iopub.status.busy": "2023-05-17T08:22:19.466303Z",
     "iopub.status.idle": "2023-05-17T08:22:20.302227Z",
     "shell.execute_reply": "2023-05-17T08:22:20.301196Z",
     "shell.execute_reply.started": "2023-05-17T08:22:19.466681Z"
    }
   },
   "outputs": [],
   "source": [
    "(_, _), (test_X, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T08:22:21.326556Z",
     "iopub.status.busy": "2023-05-17T08:22:21.326144Z",
     "iopub.status.idle": "2023-05-17T08:22:22.907209Z",
     "shell.execute_reply": "2023-05-17T08:22:22.906182Z",
     "shell.execute_reply.started": "2023-05-17T08:22:21.326521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "trained_model = keras.models.load_model('checkpoint_model')\n",
    "test_X = test_X.astype(\"float\")\n",
    "pr_y = trained_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T08:22:22.909889Z",
     "iopub.status.busy": "2023-05-17T08:22:22.909473Z",
     "iopub.status.idle": "2023-05-17T08:22:22.917005Z",
     "shell.execute_reply": "2023-05-17T08:22:22.915840Z",
     "shell.execute_reply.started": "2023-05-17T08:22:22.909854Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y = np.argmax(pr_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T08:22:27.891466Z",
     "iopub.status.busy": "2023-05-17T08:22:27.891075Z",
     "iopub.status.idle": "2023-05-17T08:22:27.900359Z",
     "shell.execute_reply": "2023-05-17T08:22:27.899224Z",
     "shell.execute_reply.started": "2023-05-17T08:22:27.891432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5046"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
